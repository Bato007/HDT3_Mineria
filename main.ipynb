{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.stats.diagnostic as diag\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import random\n",
    "import sklearn.cluster as cluster\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "import sklearn.preprocessing\n",
    "import pyclustertend \n",
    "from sklearn.cluster import Birch\n",
    "np.warnings.filterwarnings('ignore', category=np.VisibleDeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global Variables\n",
    "random.seed(123)\n",
    "number_clusters = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis Exploratorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable classification\n",
    "train_data = pd.read_csv('./data/train.csv', encoding = \"ISO-8859-1\")\n",
    "test_data = pd.read_csv('./data/test.csv', encoding = \"ISO-8859-1\")\n",
    "variables = pd.read_csv('./data/variables.txt', encoding = \"ISO-8859-1\")\n",
    "quant_vars = list(variables.loc[(variables['Clasification'] == 'Cuantitativa')]['Variable'].values)\n",
    "quali_vars = list(variables.loc[(variables['Clasification'] == 'Cualitativa')]['Variable'].values)[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando las variables numericas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[quant_vars].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in quant_vars:\n",
    "    data = train_data[var].dropna(how='all', axis=0)\n",
    "    \n",
    "    # Gráfico\n",
    "    sns.displot(data, kde=True)\n",
    "\n",
    "    # Mostrando normalidad\n",
    "    print('\\033[1m' + var + '\\033[0m' + ': Kurtosis:', stats.kurtosis(data), 'Skewness:', stats.skew(data), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando las variables categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in quali_vars:\n",
    "  plt.figure(figsize=(20,5))\n",
    "  train_data[var].value_counts().plot(kind='bar')\n",
    "  plt.show()\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analizando la variable de interes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewness and kurtosis\n",
    "print('Skewness: %f' % train_data['SalePrice'].skew())\n",
    "print('Kurtosis: %f' % train_data['SalePrice'].kurt())\n",
    "print('\\n---Describe---')\n",
    "train_data['SalePrice'].describe([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.65, 0.7, 0.8, 0.9, 0.95])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat,p = stats.shapiro(train_data[[\"SalePrice\"]].dropna())\n",
    "print('Kolmogorov-Smirnov:\\np=%f\\n'% p)\n",
    "ks_statistic, p_value = diag.lilliefors(train_data[[\"SalePrice\"]].dropna())\n",
    "print('Lilliefors:\\nks=%f\\np=%f'%(ks_statistic,p_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.displot(train_data['SalePrice'], kde=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(x=train_data[\"SalePrice\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 10 #number of variables for heatmap\n",
    "corrmat = train_data.corr()\n",
    "cols = corrmat.nlargest(k, 'SalePrice')['SalePrice'].index\n",
    "cm = np.corrcoef(train_data[cols].values.T)\n",
    "sns.set(font_scale=1.25)\n",
    "hm = sns.heatmap(cm, cbar=True, annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()\n",
    "cols = ['SalePrice', 'OverallQual', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath', 'YearBuilt']\n",
    "sns.pairplot(train_data[cols], height= 3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = train_data.isnull().sum().sort_values(ascending=False)\n",
    "percent = (train_data.isnull().sum()/train_data.isnull().count()).sort_values(ascending=False)\n",
    "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "missing_data.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis de grupos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que se puede realizar clustering\n",
    "# Cualitativa\n",
    "groups = ['OverallQual', 'YearBuilt']\n",
    "stamp = groups[0]\n",
    "aux = train_data.groupby(by=stamp)\n",
    "tags_list = list(np.array(train_data[[stamp]]))\n",
    "tag_group = list(aux.groups.keys())\n",
    "tags = []\n",
    "tag_to_number = {}\n",
    "number_to_taga = {}\n",
    "\n",
    "for i in range(len(tag_group)): \n",
    "  tag_to_number[tag_group[i]] = i\n",
    "  number_to_taga[i] = tag_group[i]\n",
    "\n",
    "for i in range(len(tags_list)): tags.append(tag_to_number[tags_list[i][0]])\n",
    "\n",
    "# Cuantitativa\n",
    "columns_analyze = ['SalePrice', 'GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath']\n",
    "cluster_data = train_data[quant_vars].fillna(0)[columns_analyze]\n",
    "X_scale = sklearn.preprocessing.scale(cluster_data)\n",
    "pyclustertend.hopkins(X_scale, len(X_scale))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeroClusters = range(1,10)\n",
    "wcss = []\n",
    "# Obtenemos 10 posibles clusters\n",
    "for i in numeroClusters:\n",
    "    # Se calcula la kmean con esa cantidad de clusters\n",
    "    kmeans = cluster.KMeans(n_clusters=i)\n",
    "    kmeans.fit(X_scale)\n",
    "    # Obtenemos la inercia\n",
    "    wcss.append(kmeans.inertia_)\n",
    "\n",
    "# Graficando\n",
    "plt.plot(numeroClusters, wcss)\n",
    "plt.xlabel(\"Cantidad de clusters\")\n",
    "plt.ylabel(\"WCSS\")\n",
    "plt.title(\"Gráfico de Codo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar el modelo\n",
    "birch_model = Birch(threshold=1.5, n_clusters=number_clusters)\n",
    "birch_model.fit(X_scale)\n",
    "\n",
    "# Obtenemos los puntos y los clusters\n",
    "birch_result = birch_model.predict(X_scale)\n",
    "\n",
    "# Graficar los clusters\n",
    "plt.scatter(X_scale[birch_result == 0, 0], X_scale[birch_result == 0, 1], s = 100, c = 'pink', label = \"Cluster 1\")\n",
    "plt.scatter(X_scale[birch_result == 1, 0], X_scale[birch_result == 1, 1], s = 100, c = 'purple', label = \"Cluster 2\")\n",
    "plt.scatter(X_scale[birch_result == 2, 0], X_scale[birch_result == 2, 1], s = 100, c = 'skyblue', label = \"Cluster 3\")\n",
    "plt.title(\"Metodo de BIRCH\")\n",
    "plt.xlabel(columns_analyze[0])\n",
    "plt.ylabel(columns_analyze[1])\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "def make_silhouette(clusterer, n_clusters, label):\n",
    "    fig, ax = plt.subplots(figsize=(1,1))\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    ax.set_xlim([-0.1, 1])\n",
    "    ax.set_ylim([0, len(X_scale) + (n_clusters + 1) * 10])\n",
    "\n",
    "    cluster_labels = clusterer.fit_predict(X_scale)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X_scale, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        n_clusters,\n",
    "        \"The average silhouette_score of\",\n",
    "        label,\n",
    "        'is:',\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    sample_silhouette_values = silhouette_samples(cluster_data, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        ax.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax.set_title(label)\n",
    "    ax.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    ax.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax.set_yticks([]) \n",
    "    ax.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "make_silhouette(birch_model, number_clusters, 'BIRCH')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Se realiza el analisis de los grupos\n",
    "confusion_birch = confusion_matrix(birch_result, tags)[0:number_clusters]\n",
    "\n",
    "# Se observar como es que estan por categoria\n",
    "def get_category(confusion_array, label=''):\n",
    "  print('\\nCONFUSION DE:', label)\n",
    "  keys = list(tag_to_number.keys())\n",
    "  for i in range(number_clusters):\n",
    "    print('\\nCLUSTER #', i+1)\n",
    "    result = list(confusion_array[i])\n",
    "    index = result.index(max(result))\n",
    "    for j in range(len(keys)):\n",
    "      print('--> %d pertenece a %s' %(result[j], keys[j]))\n",
    "    print('Podemos asegurar que es el grupo de: %s con %d' %(keys[index], result[index]))\n",
    "  \n",
    "get_category(confusion_birch, 'BIRCH - ' + stamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creación de modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Inciso 4</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de percentiles para Caro (75-100), Moderado(25-50), Barato(0-25)\n",
    "modeling_data = cluster_data\n",
    "modeling_data['Category'] = 'Caro'\n",
    "modeling_data.loc[modeling_data['SalePrice']<214000,'Category'] = 'Moderado'\n",
    "modeling_data.loc[modeling_data['SalePrice']<129975,'Category'] = 'Barato'\n",
    "print(modeling_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_data.groupby(by=[\"Category\"]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting x and y axis\n",
    "modeling_data['Category'] = modeling_data['Category'].astype('category')\n",
    "y = modeling_data.pop('Category')\n",
    "x = modeling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size=0.3, train_size = 0.7, random_state=13)\n",
    "\n",
    "# Verificación seed.\n",
    "print(xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Inciso 6</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree clasifier \n",
    "tree_created = DecisionTreeClassifier(max_depth = 3, random_state = 42)\n",
    "tree_created = tree_created.fit(xtrain, ytrain)\n",
    "tree.plot_tree(tree_created, feature_names = modeling_data.columns, class_names = ['0', '1', '2'], filled = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Inciso 7</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regretion_data = cluster_data\n",
    "yr = regretion_data.pop('SalePrice')\n",
    "xr = regretion_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrainr, xtestr, ytrainr, ytestr = train_test_split(xr, yr, test_size=0.3, train_size = 0.7, random_state=612)\n",
    "\n",
    "# Verificación seed.\n",
    "print(xtestr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision tree regretion (Lo intenté :p)\n",
    "tree_regretion_created = DecisionTreeClassifier(max_depth = 10, random_state = 45)\n",
    "tree_regretion_created = tree_regretion_created.fit(xtrainr, ytrainr)\n",
    "# tree.plot_tree(tree_regretion_created, feature_names = modeling_data.columns, filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_test_analyze = ['GrLivArea', 'GarageCars', 'TotalBsmtSF', 'FullBath']\n",
    "test_pred = test_data[columns_test_analyze].fillna(0)\n",
    "price_pred = tree_regretion_created.predict(test_pred)\n",
    "print(price_pred)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c33184972b48748d94ddd34e441bc25e543b9b1491b698e37ff4356c126c0090"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
